{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f47cee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số bài: 2746\n",
      "Các cột có trong file:\n",
      "['url', 'title', 'pub_date', 'year', 'preview', 'raw_html_path']\n",
      "Xem thử vài dòng đầu:\n",
      "                                                 url  \\\n",
      "0  https://nld.com.vn/tien-ve-clb-tp-hcm-ghi-ban-...   \n",
      "1  https://nld.com.vn/than-y-cua-tuyen-viet-nam-t...   \n",
      "\n",
      "                                               title    pub_date    year  \\\n",
      "0  Tiền vệ CLB TP HCM ghi bàn thắng đẹp nhất thán...  2025-02-12  2025.0   \n",
      "1     \"Thần y\" của tuyển Việt Nam tại ASEAN Cup 2024  2025-01-27  2025.0   \n",
      "\n",
      "                                             preview  \\\n",
      "0  VPF vừa công bố các danh hiệu giành cho đội bó...   \n",
      "1  Trong bóng đá, bên cạnh những màn trình diễn d...   \n",
      "\n",
      "                                       raw_html_path  \n",
      "0  raw_html\\20251010\\2c3c1d99e184152436010a92258d...  \n",
      "1  raw_html\\20251010\\668441722221dc12012bc72f3e07...  \n",
      "Ví dụ nội dung HTML gốc (1000 ký tự đầu):\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"vi\">\n",
      "<head>\n",
      "    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\"/>\n",
      "    <title>Tiền vệ CLB TP HCM ghi bàn thắng đẹp nhất tháng 1 V-League 2024-2025</title>\n",
      "    <script type=\"text/javascript\">\n",
      "    window.AviviD = window.AviviD || {settings:{},status:{}}; AviviD.web_id = \"nldvn\"; AviviD.category_id = \"20250318000002\"; AviviD.tracking_platform = 'likr'; (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src= 'https://www.googletagmanager.com/gtm.js?id='+i+dl+'&timestamp='+new Date().getTime();f.parentNode.insertBefore(j,f); })(window,document,'script','dataLayer','GTM-W9F4QDN'); (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src= 'https://www.googletag\n",
      "Đã đọc xong toàn bộ file HTML, có thể xử lý nội dung tiếp theo.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import os\n",
    "\n",
    "# ==================== ĐỌC FILE JSONL ====================\n",
    "file_path = r\"C:\\Users\\vinh\\Desktop\\bs4\\data\\traffic_2025_clean.jsonl\"\n",
    "\n",
    "data = []\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            obj = json.loads(line)\n",
    "            data.append(obj)\n",
    "        except Exception as e:\n",
    "            print(\"Lỗi đọc dòng:\", e)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Tổng số bài:\", len(df))\n",
    "print(\"Các cột có trong file:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"Xem thử vài dòng đầu:\")\n",
    "print(df.head(2))\n",
    "\n",
    "# ==================== ĐỌC NỘI DUNG HTML ====================\n",
    "def read_html_auto(path):\n",
    "    # kiểm tra file có tồn tại hay không\n",
    "    if not os.path.exists(path):\n",
    "        print(\"⚠️ Không tìm thấy file:\", path)\n",
    "        return \"\"\n",
    "    \n",
    "    try:\n",
    "        # đọc 2 byte đầu để nhận dạng có bị nén gzip không\n",
    "        with open(path, \"rb\") as f:\n",
    "            head = f.read(2)\n",
    "\n",
    "        # nếu có nén gzip\n",
    "        if head == b\"\\x1f\\x8b\":\n",
    "            with gzip.open(path, \"rt\", encoding=\"utf-8\", errors=\"ignore\") as fin:\n",
    "                html_code = fin.read()\n",
    "        else:\n",
    "            # nếu không nén\n",
    "            with open(path, \"rt\", encoding=\"utf-8\", errors=\"ignore\") as fin:\n",
    "                html_code = fin.read()\n",
    "        return html_code\n",
    "    except Exception as e:\n",
    "        print(\"❌ Lỗi đọc file HTML:\", e)\n",
    "        return \"\"\n",
    "\n",
    "# tạo cột mới để lưu nội dung HTML\n",
    "df[\"html_content\"] = df[\"raw_html_path\"].apply(read_html_auto)\n",
    "\n",
    "print(\"Ví dụ nội dung HTML gốc (1000 ký tự đầu):\")\n",
    "print(df[\"html_content\"].iloc[0][:1000])\n",
    "\n",
    "# ==================== KIỂM TRA ====================\n",
    "print(\"Đã đọc xong toàn bộ file HTML, có thể xử lý nội dung tiếp theo.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5825482",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m df.iterrows():\n\u001b[32m      6\u001b[39m         rec = {\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mhtml_content\u001b[39m\u001b[33m\"\u001b[39m: row[\u001b[33m\"\u001b[39m\u001b[33mhtml_content\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      9\u001b[39m         }\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m         f.write(json.dumps(rec, ensure_ascii=\u001b[38;5;28;01mFalse\u001b[39;00m) + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Đã lưu toàn bộ nội dung HTML vào:\u001b[39m\u001b[33m\"\u001b[39m, out_file)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ==================== LƯU FILE ====================\n",
    "out_file = r\"C:\\Users\\vinh\\Desktop\\bs4\\data\\traffic_html_full.jsonl\"\n",
    "\n",
    "with open(out_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for i, row in df.iterrows():\n",
    "        rec = {\n",
    "            \n",
    "            \"html_content\": row[\"html_content\"]\n",
    "        }\n",
    "        f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"✅ Đã lưu toàn bộ nội dung HTML vào:\", out_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445cd7ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efd5726e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã xử lý xong! File kết quả: tienxuly_cleaned.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "input_file = \"traffic_html_full.jsonl\"\n",
    "output_file = \"tienxuly_cleaned.jsonl\"\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as fin, \\\n",
    "     open(output_file, \"w\", encoding=\"utf-8\") as fout:\n",
    "\n",
    "    for line in fin:\n",
    "        try:\n",
    "            obj = json.loads(line)\n",
    "            html = obj.get(\"html_content\", \"\")\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "            # --- Tiêu đề ---\n",
    "            title_tag = soup.find(\"h1\", class_=\"title\")\n",
    "            title = title_tag.text.strip() if title_tag else \"\"\n",
    "\n",
    "            # --- Mô tả ngắn ---\n",
    "            summary_tag = soup.find(\"p\", class_=\"sapo\")\n",
    "            summary = summary_tag.text.strip() if summary_tag else \"\"\n",
    "\n",
    "            # --- Nội dung bài viết ---\n",
    "            body_tag = soup.find(\"div\", class_=\"contentdetail\")\n",
    "            if body_tag:\n",
    "                paragraphs = [p.get_text(\" \", strip=True) for p in body_tag.find_all(\"p\") if p.get_text(strip=True)]\n",
    "                content = \"\\n\".join(paragraphs)\n",
    "            else:\n",
    "                content = \"\"\n",
    "\n",
    "            # --- Gộp kết quả ---\n",
    "            result = {\n",
    "                \"title\": title,\n",
    "                \"summary\": summary,\n",
    "                \"content\": content\n",
    "            }\n",
    "\n",
    "            fout.write(json.dumps(result, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Lỗi:\", e)\n",
    "\n",
    "print(\"✅ Đã xử lý xong! File kết quả:\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b20cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d60a249f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số bài: 345\n",
      "✅ Đã xử lý xong và lưu vào file: news_cleaned.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# ==================== ĐỌC FILE JSONL ====================\n",
    "file_path = r\"C:\\Users\\vinh\\Desktop\\bs4\\data\\traffic_html_full.jsonl\"\n",
    "\n",
    "data = []\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            obj = json.loads(line)\n",
    "            data.append(obj)\n",
    "        except Exception as e:\n",
    "            print(\"Lỗi đọc dòng:\", e)\n",
    "\n",
    "print(\"Tổng số bài:\", len(data))\n",
    "\n",
    "# ==================== LÀM SẠCH NỘI DUNG HTML ====================\n",
    "cleaned_news = []\n",
    "\n",
    "for item in data:\n",
    "    try:\n",
    "        html = item.get(\"html_content\", \"\")\n",
    "\n",
    "        soup = BeautifulSoup(html, \"html.parser\") # or 'lxml'\n",
    "\n",
    "        # --- Crawl dữ liệu ---\n",
    "        # Tiêu đề\n",
    "        title_tag = soup.find('h1', class_='title-detail')\n",
    "        title = title_tag.text.strip() if title_tag else None\n",
    "\n",
    "        # Thời gian\n",
    "        time_tag = soup.find('div', class_='header-content width_common')\n",
    "        time_info = time_tag.text.strip() if time_tag else None\n",
    "\n",
    "        # Tóm tắt\n",
    "        summary_tag = soup.find('p', class_='description')\n",
    "        summary = summary_tag.text.strip() if summary_tag else None\n",
    "\n",
    "        # Nội dung bài viết\n",
    "        content_tag = soup.find('article', class_='fck_detail ')\n",
    "        if content_tag:\n",
    "            paragraphs = [p.text.strip() for p in content_tag.find_all('p') if p.text.strip()]\n",
    "            content = \"\\n\".join(paragraphs)\n",
    "        else:\n",
    "            content = None\n",
    "\n",
    "        # Lấy cả phần nội dung mở rộng\n",
    "        full_noi_dung_tag = soup.find('div', class_='sidebar-1')\n",
    "        full_noi_dung = full_noi_dung_tag.text.strip() if full_noi_dung_tag else None\n",
    "\n",
    "        news_data = {\n",
    "            \"url\": url,\n",
    "            \"title\": title,\n",
    "            \"time\": time_info,\n",
    "            \"summary\": summary,\n",
    "            \"content\": full_noi_dung if full_noi_dung else content\n",
    "        }\n",
    "\n",
    "        cleaned_news.append(news_data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Lỗi xử lý bài:\", e)\n",
    "\n",
    "# ==================== LƯU KẾT QUẢ ====================\n",
    "with open(r\"C:\\Users\\vinh\\Desktop\\bs4\\news_cleaned.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in cleaned_news:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"✅ Đã xử lý xong và lưu vào file: news_cleaned.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5645d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
